{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbLnxHPVlmy-"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV3Small, MobileNetV3Large, NASNetMobile\n",
        "\n",
        "seed = 199 \n",
        "tf.random.set_seed(seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPiM5rxvmDUR",
        "outputId": "d22b8e14-80dc-47ee-ac4b-b602b0ffd9d5"
      },
      "source": [
        "!bash get_data.sh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading Dataset\n",
            "kagglecatsanddogs_3 100%[===================>] 786.68M   110MB/s    in 8.7s    \n",
            "Downloading...\n",
            "From: https://drive.google.com/u/0/uc?id=10NIeg2v6b9SzBBkqzbxUT_xTTgzIjsmv\n",
            "To: /content/Dataset/101_ObjectCategories.tar.gz\n",
            "132MB [00:01, 84.0MB/s]\n",
            "Unziping... OK\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6xd2tHToIoW"
      },
      "source": [
        "base_path = '/content/Dataset'\n",
        "SHAPE = (224,224,3)\n",
        "batch_size = 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9O42gJumFZW",
        "outputId": "675183ee-5282-4635-d1d5-d92ef183825c"
      },
      "source": [
        "datagen = ImageDataGenerator(validation_split=0.1)\n",
        "\n",
        "\n",
        "train_generator = datagen.flow_from_directory(\n",
        "            base_path,\n",
        "            target_size = (SHAPE[0], SHAPE[1]),\n",
        "            batch_size = batch_size,\n",
        "            class_mode =  'binary',\n",
        "            shuffle = True,\n",
        "            seed = seed,\n",
        "            classes = ['Cats', 'NonCats'],\n",
        "            subset = 'training'\n",
        "    )\n",
        "\n",
        "test_generator = datagen.flow_from_directory(\n",
        "            base_path,\n",
        "            target_size = (SHAPE[0], SHAPE[1]),\n",
        "            batch_size = batch_size,\n",
        "            class_mode =  'binary',\n",
        "            shuffle = True,\n",
        "            seed = seed,\n",
        "            classes = ['Cats', 'NonCats'],\n",
        "            subset = 'validation'\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 19480 images belonging to 2 classes.\n",
            "Found 2163 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1znCHprmqF4Q"
      },
      "source": [
        "def get_model(base_model, input_shape):\n",
        "\n",
        "    inputs = tf.keras.Input(shape=input_shape)\n",
        "\n",
        "    x = base_model(inputs, training=False)\n",
        "\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "    outputs = tf.keras.layers.Dense(1)(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "                loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "                metrics=tf.keras.metrics.BinaryAccuracy()) \n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhnasuWIo0bG",
        "outputId": "39c03dca-c57d-4e58-ac32-111857340b07"
      },
      "source": [
        "MNV3Small = MobileNetV3Small(weights = 'imagenet', include_top = False, input_shape = SHAPE, minimalistic=True)\n",
        "MNV3Small.trainable = False\n",
        "\n",
        "model = get_model(MNV3Small, SHAPE)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v3/weights_mobilenet_v3_small_minimalistic_224_1.0_float_no_top.h5\n",
            "4497408/4491912 [==============================] - 0s 0us/step\n",
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_9 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "MobilenetV3small (Functional (None, 7, 7, 1024)        1031848   \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_3 ( (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 1025      \n",
            "=================================================================\n",
            "Total params: 1,032,873\n",
            "Trainable params: 1,025\n",
            "Non-trainable params: 1,031,848\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMCRDK6ZZ4Mr",
        "outputId": "9488ab45-e1e0-458c-e86d-d10b641bd835"
      },
      "source": [
        "model.fit(train_generator, epochs=10, validation_data=test_generator)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "609/609 [==============================] - 469s 769ms/step - loss: 0.0512 - binary_accuracy: 0.9838 - val_loss: 0.1484 - val_binary_accuracy: 0.9191\n",
            "Epoch 2/10\n",
            "609/609 [==============================] - 471s 773ms/step - loss: 0.0479 - binary_accuracy: 0.9842 - val_loss: 0.1464 - val_binary_accuracy: 0.9214\n",
            "Epoch 3/10\n",
            "609/609 [==============================] - 476s 781ms/step - loss: 0.0457 - binary_accuracy: 0.9854 - val_loss: 0.1505 - val_binary_accuracy: 0.9172\n",
            "Epoch 4/10\n",
            "609/609 [==============================] - 477s 784ms/step - loss: 0.0463 - binary_accuracy: 0.9851 - val_loss: 0.1572 - val_binary_accuracy: 0.9145\n",
            "Epoch 5/10\n",
            "609/609 [==============================] - 475s 779ms/step - loss: 0.0446 - binary_accuracy: 0.9851 - val_loss: 0.1295 - val_binary_accuracy: 0.9325\n",
            "Epoch 6/10\n",
            "609/609 [==============================] - 478s 785ms/step - loss: 0.0445 - binary_accuracy: 0.9860 - val_loss: 0.1272 - val_binary_accuracy: 0.9413\n",
            "Epoch 7/10\n",
            "609/609 [==============================] - 471s 774ms/step - loss: 0.0444 - binary_accuracy: 0.9863 - val_loss: 0.1450 - val_binary_accuracy: 0.9270\n",
            "Epoch 8/10\n",
            "609/609 [==============================] - 470s 771ms/step - loss: 0.0417 - binary_accuracy: 0.9869 - val_loss: 0.1446 - val_binary_accuracy: 0.9260\n",
            "Epoch 9/10\n",
            "609/609 [==============================] - 479s 786ms/step - loss: 0.0414 - binary_accuracy: 0.9868 - val_loss: 0.1300 - val_binary_accuracy: 0.9362\n",
            "Epoch 10/10\n",
            "609/609 [==============================] - 476s 782ms/step - loss: 0.0404 - binary_accuracy: 0.9874 - val_loss: 0.1160 - val_binary_accuracy: 0.9482\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2e8ff07f50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    }
  ]
}