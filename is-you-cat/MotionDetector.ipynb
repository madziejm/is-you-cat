{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MotionDetector.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Yg9qBOHnQNS",
        "outputId": "8dd3ebc0-9988-47b8-fb4f-32eb8e7348d4"
      },
      "source": [
        "!pip install torchinfo"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/d3/11f9901d75f4d105b2b1700c81f83579fd33c4cf0ec88bb7a165d96c7bb4/torchinfo-0.1.5-py3-none-any.whl\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-0.1.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4amTt43YWx_A"
      },
      "source": [
        "import torch\n",
        "import cv2\n",
        "import time\n",
        "\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "from torchvision import transforms\n",
        "from google.colab.patches import cv2_imshow\n",
        "from IPython.display import clear_output\n",
        "from torchinfo import summary\n",
        "\n",
        "import math"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wl7Wp0meGWsL"
      },
      "source": [
        "def video_from_frames(filename, frames):\n",
        "    vw = cv2.VideoWriter(\"filename\", cv2.VideoWriter_fourcc(*\"MJPG\"), 15, (640,480))\n",
        "\n",
        "    for frame in video:\n",
        "        vw.write(frame)\n",
        "\n",
        "    vw.release()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDptxKnDA5mm"
      },
      "source": [
        "#Phase Correlation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgEnVhIEA3E_"
      },
      "source": [
        "def test_setting_phase_corelation(video_cap, dp_threshold):\n",
        "\n",
        "    u_frame = None\n",
        "    u_frame_value = None\n",
        "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "    org = (10, 50)\n",
        "    fontScale = 2\n",
        "    color = (255, 0, 0)\n",
        "    thickness = 2\n",
        "    video = []\n",
        "    ess = 0\n",
        "    time = 1\n",
        "    \n",
        "    while (video_cap.isOpened()):\n",
        "        ret, frame = video_cap.read()\n",
        "        \n",
        "        if ret == True:\n",
        "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "            \n",
        "            if u_frame is None:\n",
        "                u_frame = frame\n",
        "                continue\n",
        "            \n",
        "            dp = cv2.phaseCorrelate(np.float32(u_frame), np.float32(frame))\n",
        "            (x,y),z = dp\n",
        "            r = math.sqrt(x*x + y*y)\n",
        "\n",
        "            if r < dp_threshold:\n",
        "                frame = cv2.putText(frame, f\"OK\", org, font, fontScale, color, thickness, cv2.LINE_AA)\n",
        "            else:\n",
        "                u_frame = frame\n",
        "                frame = cv2.putText(frame, f\"NOTOK\", org, font, fontScale, color, thickness, cv2.LINE_AA)\n",
        "                ess += 1\n",
        "            \n",
        "            video.append(frame)\n",
        "            time += 1\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    print(ess/time)\n",
        "    \n",
        "    video_cap.release()\n",
        "    return video"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBksBHv9CvXm"
      },
      "source": [
        "cap = cv2.VideoCapture('/content/output.mp4')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nospg07vCx5W",
        "outputId": "ac20bc27-bd63-4b9a-e552-c43de27d97f3"
      },
      "source": [
        "video = test_setting(cap, 20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.35342465753424657\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6oVtqchGjpy"
      },
      "source": [
        "video_from_frames(\"output.avi\", video)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ns_GMpSA1I9"
      },
      "source": [
        "# Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "astecjPoW6Mu"
      },
      "source": [
        "model = torch.load('/content/drive/MyDrive/Models/MobileNetV3_small_torch_h')\n",
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aklf_LrVYF8q"
      },
      "source": [
        "image_net_transforms = transforms.Compose(\n",
        "        [\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Resize(256),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "        ]\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UixqkBXFb5C0"
      },
      "source": [
        "def split_network(model, index):\n",
        "    network_1 = nn.Sequential(model[0][:index])\n",
        "    network_2 = nn.Sequential(*list(model[0][index:]) + list(model[1:]))\n",
        "    return network_1,network_2"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQAfSsB7eaAE"
      },
      "source": [
        "class DefaultComparator():\n",
        "    def compare(self, n1, n2):\n",
        "        raise NotImplementedError\n",
        "\n",
        "class MeanSquareComparator(DefaultComparator):\n",
        "    def __init__(self, threshold):\n",
        "        self.threshold = threshold\n",
        "    \n",
        "    def compare(self, o1, o2):\n",
        "        return torch.mean((o1-o2)**2) < self.threshold, torch.mean((o1-o2)**2)\n",
        "\n",
        "class ZBYCHUComparator(DefaultComparator):\n",
        "    def __init__(self, threshold):\n",
        "        self.threshold = threshold\n",
        "    \n",
        "    def compare(self, o1, o2):\n",
        "        return torch.mean((o1-o2)**2) < (torch.mean(o1**2) * self.threshold), torch.mean((o1-o2)**2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQOMKi4XW8tr"
      },
      "source": [
        "def test_setting_neural_netowrk(video_cap, network_1, comparator):\n",
        "\n",
        "    u_frame = None\n",
        "    u_frame_value = None\n",
        "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "    org = (10, 50)\n",
        "    fontScale = 2\n",
        "    color = (255, 0, 0)\n",
        "    thickness = 2\n",
        "\n",
        "\n",
        "    time = 0\n",
        "    ess = 0\n",
        "    video = []\n",
        "    \n",
        "    while (video_cap.isOpened()):\n",
        "        ret, frame = video_cap.read()\n",
        "        if ret == True:\n",
        "            \n",
        "            if u_frame is None:\n",
        "                u_frame = frame\n",
        "                u_frame_value = network_1(image_net_transforms(frame).view(1,3,224,224))\n",
        "                continue\n",
        "\n",
        "            frame_value = network_1(image_net_transforms(frame).view(1,3,224,224))\n",
        "            is_ok, value = comparator.compare(frame_value, u_frame_value)\n",
        "            \n",
        "            if is_ok:\n",
        "                frame = cv2.putText(frame, f\"OK\", org, font, fontScale, color, thickness, cv2.LINE_AA)\n",
        "            else:\n",
        "                ess += 1\n",
        "                u_frame = frame\n",
        "                u_frame_value = frame_value\n",
        "                frame = cv2.putText(frame, f\"NOTOK\", org, font, fontScale, color, thickness, cv2.LINE_AA)\n",
        "            \n",
        "            video.append(frame)\n",
        "            time += 1\n",
        "        else:\n",
        "            break\n",
        "    print(ess/time)\n",
        "    \n",
        "    video_cap.release()\n",
        "    return video"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_8xmEZgcccG"
      },
      "source": [
        "comparator = ZBYCHUComparator(0.8)\n",
        "n1,n2 = split_network(model, 3)\n",
        "cap = cv2.VideoCapture('/content/output.mp4')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X18xG8qYxjtm",
        "outputId": "a38d3b7e-a4b5-4172-8b69-84868f289e9a"
      },
      "source": [
        "video = test_setting(cap, n1, comparator)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.41838134430727025\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-xv4nt7JucZ"
      },
      "source": [
        "video_from_frames(\"output.avi\", video)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4em1tTOBMR9q"
      },
      "source": [
        "n1,n2 = split_network(model, 3)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rfq3vQ7sMSOq"
      },
      "source": [
        "torch.save(n1, \"MobilenetV3_torch_first\")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhhvL58-ModP"
      },
      "source": [
        "torch.save(n2, \"MobilenetV3_torch_second\")"
      ],
      "execution_count": 12,
      "outputs": []
    }
  ]
}