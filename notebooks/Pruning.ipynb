{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pruning",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkBn-LrEqrxB",
        "outputId": "2a6a9f41-b651-4915-addb-57306eaf9d9c"
      },
      "source": [
        "!pip install torchinfo"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/d3/11f9901d75f4d105b2b1700c81f83579fd33c4cf0ec88bb7a165d96c7bb4/torchinfo-0.1.5-py3-none-any.whl\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-0.1.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pp0arGnoplrF",
        "outputId": "7b5288a5-d15a-444e-c4cb-b1e684e2f659"
      },
      "source": [
        "import os\n",
        "import gc\n",
        "from copy import deepcopy\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchinfo import summary\n",
        "\n",
        "from tqdm import tqdm\n",
        "from torchvision import datasets, transforms\n",
        "import torchvision.models as models\n",
        "\n",
        "%pylab inline"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsiUpb5UHcwm"
      },
      "source": [
        "torch.manual_seed(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ahwp4-8qrA6E"
      },
      "source": [
        "!bash get_data.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3FF0Mo35IQAD",
        "outputId": "e7ee6bf1-5678-4261-8b78-04ecda74efeb"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4Ug5S35a4op"
      },
      "source": [
        "## Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RueZGizxa7iO"
      },
      "source": [
        "def save_model(path, model):\n",
        "    example = torch.rand(1, 3, 224, 224)\n",
        "    traced_script_module = torch.jit.trace(model.cpu(), example)\n",
        "    traced_script_module.save(path+\"_trace\")\n",
        "    torch.save(model, path+\"_torch\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmgMH_BLQFoH"
      },
      "source": [
        "## Training\n",
        "This cell uses starter code from University of Wrocław Neural Network Course - [Assignment 3](https://github.com/janchorowski/dl_uwr)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEZD6CRIviGU"
      },
      "source": [
        "def compute_error_rate(model, data_loader, cuda=True, verbose = False, delta = 0.5, infer = False):\n",
        "    model.eval()\n",
        "    num_errs = 0.0\n",
        "    num_examples = 0\n",
        "    pred_fun = nn.Sigmoid()\n",
        "    \n",
        "    resmap = []\n",
        "    for x, y in data_loader:\n",
        "        if cuda:\n",
        "            x = x.cuda()\n",
        "            y = y.cuda()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model.forward(x).view(-1)\n",
        "            predictions = pred_fun(outputs) > delta\n",
        "            num_errs += (predictions != y).sum().item()\n",
        "            num_examples += x.size(0)\n",
        "            \n",
        "            if infer:\n",
        "                for out, dey in zip(outputs, y):\n",
        "                    resmap.append((float(pred_fun(out)), int(dey)))\n",
        "    \n",
        "    if infer:\n",
        "        sorted_resmap = list(sorted(resmap))\n",
        "        all_zero_labels, all_one_labels = 0, 0\n",
        "        for _, label in sorted_resmap:\n",
        "            if label == 0:\n",
        "                all_zero_labels += 1\n",
        "            else:\n",
        "                all_one_labels += 1\n",
        "                \n",
        "        all_labels = all_zero_labels + all_one_labels\n",
        "        \n",
        "        \n",
        "        # na początku mówimy że delta = 0.0\n",
        "        # mówimy że wszystko > 0.0 traktujemy jako 1.\n",
        "        # wtedy, poprawnie klasyfikujemy wszystkie 1, ale wszystkie zera mylimy.\n",
        "        \n",
        "        missclasified_ones = 0\n",
        "        missclasified_zeros = all_zero_labels\n",
        "        \n",
        "        best_err = 10.0\n",
        "        delta = 0.0\n",
        "        for prob, label in sorted_resmap:\n",
        "            if label == 0:\n",
        "                #przesunęliśmy się w prawo, i dodaliśmy zero w lewo. To znaczy że teraz je poprawnie klasyf.\n",
        "                missclasified_zeros -= 1\n",
        "            else:\n",
        "                #przesunęliśmy się w prawo, i dodaliśmy jeden w lewo. To znaczy że teraz je źle klasyf.\n",
        "                missclasified_ones += 1\n",
        "            \n",
        "            t_rate = (missclasified_zeros + missclasified_ones)/all_labels\n",
        "            if t_rate < best_err:\n",
        "                best_err = t_rate\n",
        "                delta = prob\n",
        "                \n",
        "        return delta, best_err\n",
        "        #print(f\"all {all_labels} zero {all_zero_labels} ones {all_one_labels}\")\n",
        "                        \n",
        "    return 100.0 * num_errs / num_examples\n",
        "\n",
        "\n",
        "def train(\n",
        "    model, \n",
        "    data_loaders, \n",
        "    optimizer, \n",
        "    criterion, \n",
        "    num_epochs=1, \n",
        "    log_every=100, \n",
        "    cuda=True,\n",
        "    verbose=True):\n",
        "\n",
        "    if cuda:\n",
        "        model.cuda()\n",
        "\n",
        "    iter_ = 0\n",
        "    epoch = 0\n",
        "    best_params = None\n",
        "    best_val_err = np.inf\n",
        "    history = {\"train_losses\": [], \"train_errs\": [], \"val_errs\": []}\n",
        "    pred_fun = nn.Sigmoid()\n",
        "\n",
        "    if verbose:\n",
        "        print(\"Training the model!\")\n",
        "        print(\"You can interrupt it at any time.\")\n",
        "    try:\n",
        "        while epoch < num_epochs:\n",
        "            model.train()\n",
        "            gc.collect()\n",
        "            epoch += 1\n",
        "\n",
        "            for x, y in data_loaders[\"train\"]:\n",
        "\n",
        "                if cuda:\n",
        "                    x = x.cuda()\n",
        "                    y = y.cuda()\n",
        "\n",
        "                iter_ += 1\n",
        "                optimizer.zero_grad()\n",
        "                out = model(x).view(-1)\n",
        "\n",
        "                loss = criterion(out, y.float())\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                predictions = pred_fun(out) > 0.5\n",
        "                err_rate = 100.0 * (predictions != y).sum() / y.size(0)\n",
        "\n",
        "                history[\"train_losses\"].append(loss.item())\n",
        "                history[\"train_errs\"].append(err_rate.item())\n",
        "\n",
        "                                \n",
        "                if iter_ % log_every == 0 and verbose:\n",
        "                    print(\n",
        "                        \"Minibatch {0: >6}  | loss {1: >5.2f} | err rate {2: >5.2f}%\".format(\n",
        "                            iter_, loss.item(), err_rate\n",
        "                        )\n",
        "                    )\n",
        "\n",
        "            val_err_rate = compute_error_rate(model, data_loaders[\"val\"], cuda)\n",
        "            history[\"val_errs\"].append((iter_, val_err_rate))\n",
        "\n",
        "            if val_err_rate < best_val_err:\n",
        "        \n",
        "                best_epoch = epoch\n",
        "                best_val_err = val_err_rate\n",
        "                best_params = [p.detach().cpu() for p in model.parameters()]\n",
        "                \n",
        "            m = \"After epoch {0: >2} | valid err rate: {1: >5.2f}% | doing {2: >3} epochs\".format(\n",
        "                epoch, val_err_rate, num_epochs\n",
        "            )\n",
        "            if verbose:\n",
        "                print(\"{0}\\n{1}\\n{0}\".format(\"-\" * len(m), m))\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        pass\n",
        "    if best_params is not None and verbose:\n",
        "        print(\"\\nLoading best params on validation set (epoch %d)\\n\" % (best_epoch))\n",
        "        with torch.no_grad():\n",
        "            for param, best_param in zip(model.parameters(), best_params):\n",
        "                param[...] = best_param\n",
        "    if verbose:\n",
        "       plot_history(history)\n",
        "\n",
        "def plot_history(history):\n",
        "    figsize(16, 4)\n",
        "    subplot(1, 2, 1)\n",
        "    train_loss = np.array(history[\"train_losses\"])\n",
        "    semilogy(np.arange(train_loss.shape[0]), train_loss, label=\"batch train loss\")\n",
        "    legend()\n",
        "\n",
        "    subplot(1, 2, 2)\n",
        "    train_errs = np.array(history[\"train_errs\"])\n",
        "    plot(np.arange(train_errs.shape[0]), train_errs, label=\"batch train error rate\")\n",
        "    val_errs = np.array(history[\"val_errs\"])\n",
        "    plot(val_errs[:, 0], val_errs[:, 1], label=\"validation error rate\", color=\"r\")\n",
        "    ylim(0, 20)\n",
        "    legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-POXajuQgF9"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pf1oNCL-Uv7f"
      },
      "source": [
        "class Subset(Dataset):\n",
        "    r\"\"\"\n",
        "    Subset of a dataset at specified indices.\n",
        "\n",
        "    Arguments:\n",
        "        dataset (Dataset): The whole Dataset\n",
        "        indices (sequence): Indices in the whole set selected for subset\n",
        "    \"\"\"\n",
        "    def __init__(self, dataset, indices, transform):\n",
        "        self.dataset = dataset\n",
        "        self.indices = indices\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        im, labels = self.dataset[self.indices[idx]]\n",
        "        return self.transform(im), labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KH2JZs9RQh1z"
      },
      "source": [
        "### Cats from catsvsdogs kaggledataset for Cat images and CalltechDataset for NonCats images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EB7urwhVbItw",
        "outputId": "0c8cb376-a28f-488d-af9c-7a049e8df702"
      },
      "source": [
        "path = 'Dataset'\n",
        "caltech_and_cats = datasets.ImageFolder(path)\n",
        "print(f\"Dataset Size: {len(caltech_and_cats)}\")\n",
        "print(f\"Dataset Classes: {caltech_and_cats.classes}\")\n",
        "print(f\"Number of Cats: {sum(np.array(caltech_and_cats.targets)==0)}\")\n",
        "print(f\"Number of NonCats: {sum(np.array(caltech_and_cats.targets)==1)}\")\n",
        "assert len(caltech_and_cats.classes) == 2, \"if not restart notebook\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset Size: 21643\n",
            "Dataset Classes: ['Cats', 'NonCats']\n",
            "Number of Cats: 12499\n",
            "Number of NonCats: 9144\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6goFOivgSexH"
      },
      "source": [
        "### Standard Imagenet Transforms ( We are using model pretrained on imagenet)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvGeWYMeSeO7"
      },
      "source": [
        "image_net_transforms = transforms.Compose(\n",
        "        [\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Resize(256),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "        ]\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hc5_dlSUSozk"
      },
      "source": [
        "### Dataset split 80-10-10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwBhdZ7iSs3I"
      },
      "source": [
        "all_indexes = np.random.permutation(len(caltech_and_cats))\n",
        "idxs = len(all_indexes)\n",
        "train_indexes = all_indexes[:int(idxs * 0.8)]\n",
        "val_indexes = all_indexes[int(idxs * 0.9):]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdqNDtX_T-Gk"
      },
      "source": [
        "# Train/Test Loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWSPjfxIsvA_"
      },
      "source": [
        "train_dataset = Subset(\n",
        "    caltech_and_cats,\n",
        "    train_indexes,\n",
        "    image_net_transforms\n",
        ")\n",
        "\n",
        "\n",
        "test_dataset = Subset(\n",
        "    caltech_and_cats,\n",
        "    val_indexes,\n",
        "    image_net_transforms\n",
        ")\n",
        "\n",
        "\n",
        "datasets_ = {\n",
        "    \"train\": train_dataset,\n",
        "    \"val\": train_dataset,\n",
        "}\n",
        "\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "train_data_loaders = {\n",
        "    \"train\": torch.utils.data.DataLoader(\n",
        "        datasets_[\"train\"], batch_size=batch_size, num_workers=2, shuffle=True),\n",
        "    \"val\": torch.utils.data.DataLoader(\n",
        "        datasets_[\"val\"], batch_size=batch_size, num_workers=2, shuffle=False)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hwZejsGcrHp"
      },
      "source": [
        "## Plain Pretrained Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCoJvVyhGR-g"
      },
      "source": [
        "model = torch.load('/content/drive/MyDrive/Models/MobileNetV3_small_torch')\n",
        "device = 'cuda'\n",
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xeaJLSjhqn3p",
        "outputId": "1441f63a-4e14-4a8d-d142-2e25093ea0ae"
      },
      "source": [
        "summary(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "======================================================================\n",
              "Layer (type:depth-idx)                        Param #\n",
              "======================================================================\n",
              "Sequential                                    --\n",
              "├─Sequential: 1-1                             --\n",
              "│    └─ConvBNActivation: 2-1                  --\n",
              "│    │    └─Conv2d: 3-1                       (432)\n",
              "│    │    └─BatchNorm2d: 3-2                  (32)\n",
              "│    │    └─Hardswish: 3-3                    --\n",
              "│    └─InvertedResidual: 2-2                  --\n",
              "│    │    └─Sequential: 3-4                   (744)\n",
              "│    └─InvertedResidual: 2-3                  --\n",
              "│    │    └─Sequential: 3-5                   (3,864)\n",
              "│    └─InvertedResidual: 2-4                  --\n",
              "│    │    └─Sequential: 3-6                   (5,416)\n",
              "│    └─InvertedResidual: 2-5                  --\n",
              "│    │    └─Sequential: 3-7                   (13,736)\n",
              "│    └─InvertedResidual: 2-6                  --\n",
              "│    │    └─Sequential: 3-8                   (57,264)\n",
              "│    └─InvertedResidual: 2-7                  --\n",
              "│    │    └─Sequential: 3-9                   (57,264)\n",
              "│    └─InvertedResidual: 2-8                  --\n",
              "│    │    └─Sequential: 3-10                  (21,968)\n",
              "│    └─InvertedResidual: 2-9                  --\n",
              "│    │    └─Sequential: 3-11                  (29,800)\n",
              "│    └─InvertedResidual: 2-10                 --\n",
              "│    │    └─Sequential: 3-12                  (91,848)\n",
              "│    └─InvertedResidual: 2-11                 --\n",
              "│    │    └─Sequential: 3-13                  (294,096)\n",
              "│    └─InvertedResidual: 2-12                 --\n",
              "│    │    └─Sequential: 3-14                  (294,096)\n",
              "│    └─ConvBNActivation: 2-13                 --\n",
              "│    │    └─Conv2d: 3-15                      (55,296)\n",
              "│    │    └─BatchNorm2d: 3-16                 (1,152)\n",
              "│    │    └─Hardswish: 3-17                   --\n",
              "├─AdaptiveAvgPool2d: 1-2                      --\n",
              "├─Flatten: 1-3                                --\n",
              "├─Linear: 1-4                                 577\n",
              "======================================================================\n",
              "Total params: 927,585\n",
              "Trainable params: 577\n",
              "Non-trainable params: 927,008\n",
              "======================================================================"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izVA4zJZhJmk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d54b169-a63a-4070-eaa7-80340b92fe66"
      },
      "source": [
        "def verify_prune(imodel):\n",
        "    allzero = 0\n",
        "    gallw = 0\n",
        "\n",
        "    for k, v in dict(imodel.named_modules()).items():\n",
        "        if ((len(list(v.children())) == 0)):\n",
        "            if str(v) not in [\n",
        "                \"Hardswish()\", \n",
        "                \"ReLU(inplace=True)\", \n",
        "                \"Identity()\", \n",
        "                \"AdaptiveAvgPool2d(output_size=1)\",\n",
        "                \"Flatten(start_dim=1, end_dim=-1)\"]:\n",
        "\n",
        "                zerow = float(torch.sum(v.weight == 0))\n",
        "                allw = float(torch.sum(v.weight > -10000000.0))\n",
        "                if v.bias != None:\n",
        "                    zerow += float(torch.sum(v.bias == 0))\n",
        "                    allw += float(torch.sum(v.bias > -10000000.0))\n",
        "\n",
        "                #print(str(v).split(\"(\")[0], 100.0 * zerow/allw)\n",
        "                allzero += zerow\n",
        "                gallw += allw\n",
        "\n",
        "    return(allzero/gallw * 100.0)\n",
        "\n",
        "print(\"prune factor\", verify_prune(model))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "prune factor 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gW-HK5XtLO8e",
        "outputId": "19a5244a-5a7a-46d9-f34c-49744001dc5c"
      },
      "source": [
        "val_err_rate = compute_error_rate(model, train_data_loaders[\"val\"], cuda = True, verbose=True)\n",
        "print(\"model val err rate\", val_err_rate)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model val err rate 2.500866350929883\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gHM_wvmGR-g",
        "outputId": "d68460bb-68da-46d7-88f5-6ec1894a2f4e"
      },
      "source": [
        "import torch.nn.utils.prune as prune\n",
        "\n",
        "def testprune(startmodel, prune_factor, cuda = True):\n",
        "    testmodel = deepcopy(startmodel)\n",
        "    parameter_to_prune = []\n",
        "    for k, v in dict(testmodel.named_modules()).items():\n",
        "        if ((len(list(v.children())) == 0)):\n",
        "            if str(v) not in [\n",
        "                \"Hardswish()\", \n",
        "                \"ReLU(inplace=True)\", \n",
        "                \"Identity()\", \n",
        "                \"AdaptiveAvgPool2d(output_size=1)\",\n",
        "                \"Flatten(start_dim=1, end_dim=-1)\"]:\n",
        "\n",
        "                parameter_to_prune.append((v, \"weight\"))\n",
        "\n",
        "    prune.global_unstructured(\n",
        "        parameter_to_prune,\n",
        "        pruning_method=prune.L1Unstructured,\n",
        "        amount=prune_factor,\n",
        "    )\n",
        "    \n",
        "    print(f\"prune target {prune_factor}\")\n",
        "    print(f\"actually pruned {verify_prune(testmodel)}\")\n",
        "    \n",
        "    delta, best_err = compute_error_rate(testmodel, train_data_loaders[\"val\"], cuda = cuda, verbose=True, infer=True)\n",
        "    print(\"best test err\", best_err, \"at\", delta)\n",
        "\n",
        "    print(\"naive delta=0.5 for validation\")\n",
        "    val_err = compute_error_rate(testmodel, train_data_loaders[\"val\"], cuda = cuda, verbose=True, delta=0.5)\n",
        "    print(f\"error {val_err}\")\n",
        "    print(f\"infered delta={delta} for validation\")\n",
        "    val_err = compute_error_rate(testmodel, train_data_loaders[\"val\"], cuda = cuda, verbose=True, delta=delta)\n",
        "    print(f\"error {val_err}\")\n",
        "\n",
        "    criterion = torch.nn.BCEWithLogitsLoss()\n",
        "    optimizer = torch.optim.Adam(testmodel.parameters(), lr=0.0001)\n",
        "    \n",
        "    print(\"retraining model\")    \n",
        "    train(testmodel, train_data_loaders, optimizer, criterion, num_epochs=3, log_every=50, cuda = True, verbose=False)\n",
        "    print(\"verify prune\")\n",
        "    print(verify_prune(testmodel))\n",
        "\n",
        "    val_err = compute_error_rate(testmodel, train_data_loaders[\"val\"], cuda = cuda, verbose=True, delta=0.5)\n",
        "    print(\"best test err\", best_err, \"at\", delta)\n",
        "\n",
        "    print(\"naive delta=0.5 for validation\")\n",
        "    val_err = compute_error_rate(testmodel, train_data_loaders[\"val\"], cuda = cuda, verbose=True, delta=0.5)\n",
        "    print(f\"error {val_err}\")\n",
        "    print(f\"infered delta={delta} for validation\")\n",
        "    val_err = compute_error_rate(testmodel, train_data_loaders[\"val\"], cuda = cuda, verbose=True, delta=delta)\n",
        "    print(f\"error {val_err}\")\n",
        "    \n",
        "    \n",
        "    return testmodel\n",
        "    \n",
        "outmodel = testprune(model, 0.50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "prune target 0.5\n",
            "actually pruned 49.5178339451371\n",
            "best test err 0.16056370567171074 at 0.6114173531532288\n",
            "naive delta=0.5 for validation\n",
            "error 31.673789996534595\n",
            "infered delta=0.6114173531532288 for validation\n",
            "error 16.056370567171076\n",
            "retraining model\n",
            "verify prune\n",
            "49.5178339451371\n",
            "best test err 0.16056370567171074 at 0.6114173531532288\n",
            "naive delta=0.5 for validation\n",
            "error 4.9844056832621\n",
            "infered delta=0.6114173531532288 for validation\n",
            "error 7.716298948827538\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JepNckZJGR-h"
      },
      "source": [
        "def save_model(path, model):\n",
        "    example = torch.rand(1, 3, 224, 224)\n",
        "    traced_script_module = torch.jit.trace(model.cpu(), example)\n",
        "    traced_script_module.save(path+\"_trace\")\n",
        "    torch.save(model, path+\"_torch\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyKI6dpTvy_0"
      },
      "source": [
        "save_model('mobilenet_v3_pruned', outmodel)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}